{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87985d8c-3fd8-4124-bba2-cf5e1e29c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1786cb3b-e3d8-4bbd-9b57-a72c6f3a8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_of_item(actual_location, desired_location, length):\n",
    "    distance = np.abs(actual_location - desired_location)\n",
    "    score = length - distance\n",
    "    # the closer you are the higher the score\n",
    "    denominator = np.log2(actual_location+1)\n",
    "    return score/denominator\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9065ffad-c077-4b96-a6d0-2b7b07024923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score_of_ranking(desired_ranking, actual_ranking):\n",
    "    score_sum = 0\n",
    "    for i in range(len(desired_ranking)):\n",
    "        item = actual_ranking[i] # this is the item that was in the ith place\n",
    "        desired_rank_of_item = desired_ranking.index(item)+1\n",
    "        score = dcg_of_item(i+1, desired_rank_of_item, len(desired_ranking))\n",
    "        score_sum += score\n",
    "    return score_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dd790bd-52b9-43b0-842d-c83a54d1e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 19:28:08.920299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-18 19:28:09.767008: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-18 19:28:09.880671: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-18 19:28:11.282050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-18 19:28:11.282189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-18 19:28:11.282197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import seaborn as sns\n",
    "from ExplainableMaximumLikelihoodCalculator import ExplainableMaximumLikelihoodCalculator\n",
    "import pysam\n",
    "from Bio import SeqIO, Seq, SeqRecord, pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from LoadDataUtils import getListOfReadsFromBamFile, getListOfReadsFromFastaFile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import shap\n",
    "from scipy.stats import chisquare\n",
    "from scipy.special import rel_entr\n",
    "fileNameSapiens =  \"data/simulatedData/human_chinese_AF346973_500samples.fas\" #File that contains 500 reads from homo sapiens\n",
    "fileNameNeanderthals =  \"data/simulatedData/Neanderthal_Goyet_KX198085_500samples.fas\" #File that contains 500 reads from neanderthal\n",
    "fileNameDenisovans =  \"data/simulatedData/denisova_kx663333_500samples.fas\" #File that contains 500 reads from denisovan\n",
    "neanderthals_500_generated = getListOfReadsFromFastaFile(fileNameNeanderthals)\n",
    "sapiens_500_generated = getListOfReadsFromFastaFile(fileNameSapiens)\n",
    "denisovan_500_samples = getListOfReadsFromFastaFile(fileNameDenisovans)\n",
    "path_to_frequencies_table = \"data/substitution_matrix.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f55dc2db-0fbb-48f7-ba5e-a29f0589dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sapiens_reference_file_names = [\n",
    "                    \"data/reference_files/human_AF346981_French.fa\",\n",
    "                     \"data/reference_files/human_AY195760_Korea.fa\",\n",
    "                      \"data/reference_files/human_AY882416_Ethiopia.fa\",\n",
    "                      \"data/reference_files/human_AY963586_Italian.fa\",\n",
    "                      \"data/reference_files/human_AY195781_Caucasian.fa\",\n",
    "                      \"data/reference_files/human_AY195757_Iraqi-Israeli.fa\",\n",
    "                      \"data/reference_files/human_AY195749_NativeAmerican.fa\"]\n",
    "neanderthals_reference_file_names = [\n",
    "                            \"data/reference_files/neanderthal_mezmaiskaya1_FM865411.fa\",\n",
    "                           \"data/reference_files/Neanderthal_Altai_KC879692.fa\",\n",
    "                           \"data/reference_files/Neanderthal_Denisova11_full_mtDNA_KU131206.fa\",\n",
    "                           \"data/reference_files/Neanderthal_Spy_94a_MG025538.fa\",\n",
    "                            \"data/reference_files/Neanderthal_Vindija33.16_AM948965.fa\",\n",
    "                            \"data/reference_files/Neanderthal_Vindija33.19_KJ533545.fa\"]\n",
    "denisovan_reference_file_names = [  \n",
    "                        \"data/reference_files/Denisova_MT576653.1.fa\",\n",
    "                        \"data/reference_files/Denisova_MT576652.1.fa\",\n",
    "                        \"data/reference_files/Denisova_4_FR695060.fa\",\n",
    "                        \"data/reference_files/Denisova_8_KT780370.fa\",\n",
    "                        \"data/reference_files/Denisova_manual_phalanx_NC_013993.fa\",\n",
    "                        \"data/reference_files/Denisova_MT576651.1.fa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e51db59-a37f-4a7d-8d6c-094e299dc5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(sap, nean, den):\n",
    "    list_before =  list(np.random.choice(sapiens_500_generated, sap)) + list(np.random.choice(neanderthals_500_generated, nean)) + list(np.random.choice(denisovan_500_samples, den))\n",
    "    l = []\n",
    "    for i in list_before:\n",
    "        l.append(str(i))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48159d07-c447-4db5-847b-10290e27dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def find_all_subsets(group):\n",
    "    all_subsets = []\n",
    "    n = len(group)\n",
    "    \n",
    "    for r in range(n + 1):\n",
    "        subsets_r = combinations(group, r)\n",
    "        all_subsets.extend(list(subsets_r))\n",
    "        \n",
    "    return all_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd15cce2-5039-434f-99ec-a90a13932b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shapley_values_for_datum(data_point, length_of_data, ml_calculator):\n",
    "    indexes_without_datum = [i for i in range(length_of_data) if i != data_point]\n",
    "    all_subsets = find_all_subsets(indexes_without_datum)\n",
    "    sum_over_all_subsets = 0 \n",
    "    for G in all_subsets:\n",
    "        g_with = [i for i in G]\n",
    "        g_with.append(data_point)\n",
    "        with_datum = ml_calculator.calc_maximum_likelihood_on_subset(subset_of_indexes=g_with).values[0]\n",
    "        without_datum = ml_calculator.calc_maximum_likelihood_on_subset(subset_of_indexes=G).values[0]\n",
    "        with_minus_without = with_datum - without_datum\n",
    "        multiplier = np.math.factorial(len(G)) * np.math.factorial(length_of_data - len(G) - 1)\n",
    "        value_for_sum = with_minus_without * multiplier \n",
    "        sum_over_all_subsets += value_for_sum\n",
    "    shapleys = sum_over_all_subsets / np.math.factorial(length_of_data)\n",
    "    return  shapleys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c85bc4b4-53e3-4ea8-a759-7ec9b455808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRankingResultsForLabel(label, ground_truth_shapleys, shaps, a_s_d, shapley_values_monte_carlo):\n",
    "    ranking_results = []\n",
    "    ground_truth_shapley_label = [i[label] for i in ground_truth_shapleys]\n",
    "    ground_shapley_label_with_index = []\n",
    "    for i in range(len(ground_truth_shapley_label)):\n",
    "        ground_shapley_label_with_index.append((ground_truth_shapley_label[i], i))\n",
    "    ground_shapley_label_with_index_sorted = sorted(ground_shapley_label_with_index, key=lambda a:a[0], reverse=True)\n",
    "    only_indexes_sorted = [i[1] for i in ground_shapley_label_with_index_sorted]\n",
    "\n",
    "    shaps_label = shaps[label][0]\n",
    "    shaps_with_index = []\n",
    "    for i in range(len(shaps_label)):\n",
    "        shaps_with_index.append((shaps_label[i], i))\n",
    "    shap_label_with_index_sorted = sorted(shaps_with_index, key=lambda a:a[0], reverse=True)\n",
    "    only_indexes_sorted_shap = [i[1] for i in shap_label_with_index_sorted]\n",
    "    ranking_result_shap = calculate_score_of_ranking(only_indexes_sorted, only_indexes_sorted_shap)\n",
    "\n",
    "    a_s_d_label = [i[label] for i in a_s_d]\n",
    "    a_s_d_index = []\n",
    "    for i in range(len(a_s_d_label)):\n",
    "        a_s_d_index.append((a_s_d_label[i], i))\n",
    "    a_s_d_with_index_sorted = sorted(a_s_d_index, key=lambda a:a[0], reverse=True)\n",
    "    only_indexes_sorted_a_s_d = [i[1] for i in a_s_d_with_index_sorted]\n",
    "    ranking_result_a_s_d = calculate_score_of_ranking(only_indexes_sorted, only_indexes_sorted_a_s_d)\n",
    "\n",
    "    monte_carlo_label = shapley_values_monte_carlo[label][0]\n",
    "    monte_carlo_label_with_index = []\n",
    "    for i in range(len(monte_carlo_label)):\n",
    "        monte_carlo_label_with_index.append((monte_carlo_label[i], i))\n",
    "    monte_carlo_label_with_index_sorted = sorted(monte_carlo_label_with_index, key=lambda a:a[0], reverse=True)\n",
    "    monte_carlo_only_indexes_sorted = [i[1] for i in monte_carlo_label_with_index_sorted]\n",
    "    ranking_result_monte_carlo = calculate_score_of_ranking(only_indexes_sorted, monte_carlo_only_indexes_sorted)\n",
    "\n",
    "    ranking_results.append((ranking_result_shap, ranking_result_a_s_d, ranking_result_monte_carlo))\n",
    "    return ranking_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0a811eb2-a68b-462a-b3f0-a978438e4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateRankingForAllALgorithms():\n",
    "    data = generate_sample(5,2,0)\n",
    "    maximum_likelihood_calculator_d_1 = ExplainableMaximumLikelihoodCalculator(data,\n",
    "                                                        ref_neanderthal_file_names=neanderthals_reference_file_names,\n",
    "                                                        ref_sapien_file_names=sapiens_reference_file_names,\n",
    "                                                        ref_denisovan_file_names=denisovan_reference_file_names,\n",
    "                                                        path_to_substitution_matrix=path_to_frequencies_table,\n",
    "                                                        number_of_jobs=-1)\n",
    "    ground_truth_shapleys = []\n",
    "    for i in range(len(data)):\n",
    "        ground_truth_shapleys.append(calculate_shapley_values_for_datum(i,len(data),maximum_likelihood_calculator_d_1))\n",
    "    shaps = maximum_likelihood_calculator_d_1.calculate_shapley_values()\n",
    "    a_s_d = maximum_likelihood_calculator_d_1.get_A_s_d_values()\n",
    "    shapley_values_monte_carlo = maximum_likelihood_calculator_d_1.estimate_shapley_values(number_of_samples_per_read = 200)[1]\n",
    "\n",
    "    results = []\n",
    "    for i in range(3):\n",
    "        result = calculateRankingResultsForLabel(i, ground_truth_shapleys, shaps, a_s_d, shapley_values_monte_carlo)\n",
    "        results.append(result)\n",
    "\n",
    "    results_shap = np.mean([i[0][0] for i in results])\n",
    "    results_a_s_d = np.mean([i[0][1] for i in results])\n",
    "    results_monte_carlo = np.mean([i[0][2] for i in results])\n",
    "\n",
    "\n",
    "    return((results_shap, results_a_s_d, results_monte_carlo))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f67c296d-bd64-4692-81dc-991713c5c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading sequences and calculating alignments to all references, this might take a while. Number of reads: \u001b[0m 7\n",
      "start working on read number 0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affc4d9aa274459b9a560c0d67e6db27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "126\n",
      "\u001b[32mStart working on read number 0 in processId 2521\u001b[0m\n",
      "\u001b[32mStart working on read number 1 in processId 2522\u001b[0m\n",
      "\u001b[32mStart working on read number 2 in processId 2523\u001b[0m\n",
      "\u001b[32mStart working on read number 3 in processId 2524\u001b[0m\u001b[32mStart working on read number 4 in processId 2525\u001b[0m\n",
      "\n",
      "\u001b[32mStart working on read number 5 in processId 2526\u001b[0m\n",
      "\u001b[32mStart working on read number 6 in processId 2527\u001b[0m\n",
      "(23.576683015630323, 22.60384455584519, 21.042519964370715)\n",
      "\u001b[34mLoading sequences and calculating alignments to all references, this might take a while. Number of reads: \u001b[0m 7\n",
      "start working on read number 0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d66b6e919d4dd7adbffce6ab3a54f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "126\n",
      "\u001b[32mStart working on read number 0 in processId 2608\u001b[0m\n",
      "\u001b[32mStart working on read number 2 in processId 2610\u001b[0m\u001b[32mStart working on read number 1 in processId 2609\u001b[0m\n",
      "\n",
      "\u001b[32mStart working on read number 3 in processId 2611\u001b[0m\u001b[32mStart working on read number 5 in processId 2613\u001b[0m\u001b[32mStart working on read number 4 in processId 2612\u001b[0m\n",
      "\n",
      "\u001b[32mStart working on read number 6 in processId 2614\u001b[0m\n",
      "\n",
      "(23.245046779953224, 21.427148882700994, 24.068485453506465)\n",
      "\u001b[34mLoading sequences and calculating alignments to all references, this might take a while. Number of reads: \u001b[0m 7\n",
      "start working on read number 0\n",
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b05a726cea4ca89ab148891e4e34e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "126\n",
      "\u001b[32mStart working on read number 0 in processId 2695\u001b[0m\n",
      "\u001b[32mStart working on read number 2 in processId 2697\u001b[0m\u001b[32mStart working on read number 1 in processId 2696\u001b[0m\u001b[32mStart working on read number 3 in processId 2698\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[32mStart working on read number 4 in processId 2699\u001b[0m\n",
      "\u001b[32mStart working on read number 5 in processId 2700\u001b[0m\n",
      "\u001b[32mStart working on read number 6 in processId 2701\u001b[0m\n",
      "(24.05357520165479, 25.089020890721415, 24.222598496904553)\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for i in range(3):\n",
    "    res = calculateRankingForAllALgorithms()\n",
    "    all_scores.append(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "03165a8c-bb30-4300-abae-103742c92318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23.576683015630323, 22.60384455584519, 21.042519964370715),\n",
       " (23.245046779953224, 21.427148882700994, 24.068485453506465),\n",
       " (24.05357520165479, 25.089020890721415, 24.222598496904553)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ca041991-123b-4929-b7a2-76e14fab0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_shap = np.mean([i[0] for i in all_scores])\n",
    "results_a_s_d = np.mean([i[1] for i in all_scores])\n",
    "results_monte_carlo = np.mean([i[2] for i in all_scores])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
